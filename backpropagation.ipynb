{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6e23638",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-21T09:57:35.435381Z",
     "iopub.status.busy": "2025-07-21T09:57:35.434368Z",
     "iopub.status.idle": "2025-07-21T09:57:37.177507Z",
     "shell.execute_reply": "2025-07-21T09:57:37.176264Z"
    },
    "papermill": {
     "duration": 1.750907,
     "end_time": "2025-07-21T09:57:37.179378",
     "exception": false,
     "start_time": "2025-07-21T09:57:35.428471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3dbcf9",
   "metadata": {
    "papermill": {
     "duration": 0.002872,
     "end_time": "2025-07-21T09:57:37.185863",
     "exception": false,
     "start_time": "2025-07-21T09:57:37.182991",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 🧠 Backpropagation: Step-by-Step with Math + Real-Life Analogy 🍰\n",
    "\n",
    "---\n",
    "\n",
    "## 🔁 What is Backpropagation?\n",
    "\n",
    "Backpropagation is the core algorithm used in training neural networks. It computes the **gradient of the loss function** with respect to each weight using the **chain rule**, and updates the weights using **gradient descent**.\n",
    "\n",
    "---\n",
    "\n",
    "## 📦 Real-Life Analogy: Baking a Cake 🍰\n",
    "\n",
    "Imagine you're baking a cake and it tastes bad (high loss). To fix it, you trace backward:\n",
    "\n",
    "- Too much sugar?\n",
    "- Not enough baking powder?\n",
    "\n",
    "You adjust ingredients based on output — that’s backpropagation! The weights are ingredients, and the taste (loss) tells you what to fix.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔢 Step-by-Step Process\n",
    "\n",
    "Assume a simple neural network:\n",
    "\n",
    "- Input layer  \n",
    "- One hidden layer with ReLU  \n",
    "- One output layer with Sigmoid  \n",
    "- Binary Cross Entropy Loss\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Step 1: Forward Pass\n",
    "\n",
    "1. Hidden layer:\n",
    "\n",
    "$$\n",
    "Z^{[1]} = W^{[1]} X + b^{[1]}\n",
    "$$\n",
    "\n",
    "$$\n",
    "A^{[1]} = \\text{ReLU}(Z^{[1]})\n",
    "$$\n",
    "\n",
    "2. Output layer:\n",
    "\n",
    "$$\n",
    "Z^{[2]} = W^{[2]} A^{[1]} + b^{[2]}\n",
    "$$\n",
    "\n",
    "$$\n",
    "A^{[2]} = \\hat{Y} = \\sigma(Z^{[2]})\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Step 2: Loss Calculation (Binary Cross-Entropy)\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = - \\left( Y \\log(\\hat{Y}) + (1 - Y) \\log(1 - \\hat{Y}) \\right)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Step 3: Backward Pass (Gradient Calculation)\n",
    "\n",
    "#### Output Layer:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial A^{[2]}} = -\\left(\\frac{Y}{A^{[2]}} - \\frac{1 - Y}{1 - A^{[2]}} \\right)\n",
    "$$\n",
    "\n",
    "Derivative of Sigmoid:\n",
    "\n",
    "$$\n",
    "\\frac{dA}{dZ} = A^{[2]} (1 - A^{[2]})\n",
    "$$\n",
    "\n",
    "Combine:\n",
    "\n",
    "$$\n",
    "\\delta^{[2]} = A^{[2]} - Y\n",
    "$$\n",
    "\n",
    "#### Gradient w.r.t Weights:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial W^{[2]}} = \\delta^{[2]} \\cdot (A^{[1]})^T\n",
    "$$\n",
    "\n",
    "#### Hidden Layer:\n",
    "\n",
    "Backpropagated error:\n",
    "\n",
    "$$\n",
    "\\delta^{[1]} = (W^{[2]})^T \\delta^{[2]} \\cdot \\text{ReLU}'(Z^{[1]})\n",
    "$$\n",
    "\n",
    "Derivative of ReLU:\n",
    "\n",
    "$$\n",
    "\\text{ReLU}'(z) = \\begin{cases} \n",
    "1 & \\text{if } z > 0 \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Gradient w.r.t Weights:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial W^{[1]}} = \\delta^{[1]} \\cdot X^T\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 🔁 Weight Update Rule\n",
    "\n",
    "Using learning rate \\( \\eta \\):\n",
    "\n",
    "$$\n",
    "W^{[l]} = W^{[l]} - \\eta \\cdot \\frac{\\partial \\mathcal{L}}{\\partial W^{[l]}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b^{[l]} = b^{[l]} - \\eta \\cdot \\frac{\\partial \\mathcal{L}}{\\partial b^{[l]}}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 🏁 Summary Table\n",
    "\n",
    "| Layer         | Error Term \\( \\delta \\)                  | Gradient w.r.t Weight              |\n",
    "|---------------|-------------------------------------------|------------------------------------|\n",
    "| Output Layer  | \\( \\delta^{[2]} = A^{[2]} - Y \\)          | \\( \\delta^{[2]} (A^{[1]})^T \\)     |\n",
    "| Hidden Layer  | \\( \\delta^{[1]} = (W^{[2]})^T \\delta^{[2]} \\cdot \\text{ReLU}'(Z^{[1]}) \\) | \\( \\delta^{[1]} X^T \\) |\n",
    "\n",
    "---\n",
    "\n",
    "## 💡 Real-Life Example Revisited: Smart Cake Baking\n",
    "\n",
    "- Bake a cake → 🍰  \n",
    "- It tastes too sweet → 😖  \n",
    "- Trace back ingredients  \n",
    "- Adjust sugar, bake again  \n",
    "- 🎯 Backpropagation in action!\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e8f732",
   "metadata": {
    "papermill": {
     "duration": 0.002521,
     "end_time": "2025-07-21T09:57:37.191014",
     "exception": false,
     "start_time": "2025-07-21T09:57:37.188493",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 🔁 Backpropagation in Deep Learning – Complete Math Walkthrough\n",
    "\n",
    "## 🧠 Objective:\n",
    "Train a neural network by minimizing a loss function using gradients computed via backpropagation.\n",
    "\n",
    "---\n",
    "\n",
    "## 🏗️ Architecture (Simple 1 Hidden Layer Network)\n",
    "\n",
    "Let’s define:\n",
    "- Input: **x** ∈ ℝⁿ  \n",
    "- Hidden layer weights: **W₁** ∈ ℝ^(h × n), biases: **b₁** ∈ ℝ^h  \n",
    "- Activation (sigmoid): **a = σ(z₁)**  \n",
    "- Output layer weights: **W₂** ∈ ℝ^(1 × h), biases: **b₂** ∈ ℝ  \n",
    "- Output: **ŷ = z₂ = W₂a + b₂**  \n",
    "- True output: **y** ∈ ℝ  \n",
    "- Loss function: Mean Squared Error (MSE)  \n",
    "  **L = ½ (y - ŷ)²**\n",
    "\n",
    "---\n",
    "\n",
    "## 🚀 Step 1: Forward Pass\n",
    "\n",
    "1. Compute linear transformation of hidden layer:  \n",
    "   **z₁ = W₁x + b₁**\n",
    "\n",
    "2. Apply activation:  \n",
    "   **a = σ(z₁)**, where **σ(z) = 1 / (1 + e^(−z))**\n",
    "\n",
    "3. Compute output:  \n",
    "   **z₂ = W₂a + b₂ = ŷ**\n",
    "\n",
    "4. Compute loss:  \n",
    "   **L = ½ (y - ŷ)²**\n",
    "\n",
    "---\n",
    "\n",
    "## 🔄 Step 2: Backward Pass (Gradient Computation using Chain Rule)\n",
    "\n",
    "### ⬅️ Gradient at Output Layer\n",
    "\n",
    "Loss:  \n",
    "**L = ½ (y - ŷ)²**  \n",
    "So:  \n",
    "**∂L/∂ŷ = -(y - ŷ)**\n",
    "\n",
    "Since:  \n",
    "**ŷ = z₂ = W₂a + b₂**,  \n",
    "We compute:  \n",
    "**∂L/∂W₂ = ∂L/∂z₂ × ∂z₂/∂W₂ = (ŷ - y) × aᵗ**  \n",
    "**∂L/∂b₂ = ∂L/∂z₂ × ∂z₂/∂b₂ = (ŷ - y)**\n",
    "\n",
    "---\n",
    "\n",
    "### ⬅️ Gradient at Hidden Layer\n",
    "\n",
    "We propagate error back:\n",
    "\n",
    "1. From output to hidden activation:  \n",
    "   **∂L/∂a = ∂L/∂z₂ × ∂z₂/∂a = (ŷ - y) × W₂**\n",
    "\n",
    "2. Apply derivative of sigmoid:  \n",
    "   Recall:  \n",
    "   **σ(z₁) = a**  \n",
    "   **σ'(z₁) = a × (1 - a)**\n",
    "\n",
    "   So:  \n",
    "   **∂L/∂z₁ = ∂L/∂a × σ'(z₁) = ((ŷ - y) × W₂) ⊙ a × (1 - a)**  \n",
    "   (⊙ = element-wise multiplication)\n",
    "\n",
    "3. Compute gradients of W₁ and b₁:  \n",
    "   **∂L/∂W₁ = ∂L/∂z₁ × ∂z₁/∂W₁ = (∂L/∂z₁) × xᵗ**  \n",
    "   **∂L/∂b₁ = ∂L/∂z₁**\n",
    "\n",
    "---\n",
    "\n",
    "## 🧮 Final Gradient Summary\n",
    "\n",
    "- **∂L/∂W₂ = (ŷ - y) × aᵗ**  \n",
    "- **∂L/∂b₂ = (ŷ - y)**  \n",
    "- **∂L/∂W₁ = ((ŷ - y) × W₂) ⊙ a × (1 - a) × xᵗ**  \n",
    "- **∂L/∂b₁ = ((ŷ - y) × W₂) ⊙ a × (1 - a)**\n",
    "\n",
    "---\n",
    "\n",
    "## 🛠️ Step 3: Weight Update (Gradient Descent)\n",
    "\n",
    "Using learning rate **η**:\n",
    "- **W₁ = W₁ - η × ∂L/∂W₁**\n",
    "- **b₁ = b₁ - η × ∂L/∂b₁**\n",
    "- **W₂ = W₂ - η × ∂L/∂W₂**\n",
    "- **b₂ = b₂ - η × ∂L/∂b₂**\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 Notes:\n",
    "\n",
    "- Vectorization is crucial for efficiency.\n",
    "- You can use ReLU instead of sigmoid:  \n",
    "  ReLU(z) = max(0, z),  \n",
    "  ReLU′(z) = 1 if z > 0 else 0\n",
    "- Use Cross-Entropy + Softmax for multi-class tasks.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 Intuition:\n",
    "\n",
    "- Forward pass gives prediction.\n",
    "- Loss measures how far prediction is from truth.\n",
    "- Backprop computes how much each weight contributed to the error.\n",
    "- Weights are updated in the direction that reduces the loss the most.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d053dbd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T09:57:37.197491Z",
     "iopub.status.busy": "2025-07-21T09:57:37.197139Z",
     "iopub.status.idle": "2025-07-21T09:57:37.201194Z",
     "shell.execute_reply": "2025-07-21T09:57:37.200532Z"
    },
    "papermill": {
     "duration": 0.008783,
     "end_time": "2025-07-21T09:57:37.202419",
     "exception": false,
     "start_time": "2025-07-21T09:57:37.193636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a81311bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T09:57:37.208483Z",
     "iopub.status.busy": "2025-07-21T09:57:37.208262Z",
     "iopub.status.idle": "2025-07-21T09:57:37.233037Z",
     "shell.execute_reply": "2025-07-21T09:57:37.232360Z"
    },
    "papermill": {
     "duration": 0.029249,
     "end_time": "2025-07-21T09:57:37.234259",
     "exception": false,
     "start_time": "2025-07-21T09:57:37.205010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cgpa</th>\n",
       "      <th>profile</th>\n",
       "      <th>lpa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cgpa  profile  lpa\n",
       "0     8        8    4\n",
       "1     7        9    5\n",
       "2     6       10    6\n",
       "3     5       12    7"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame([[8,8,4],[7,9,5],[6,10,6],[5,12,7]],columns=['cgpa','profile','lpa'])\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ba5883b4",
   "metadata": {
    "papermill": {
     "duration": 0.002666,
     "end_time": "2025-07-21T09:57:37.239802",
     "exception": false,
     "start_time": "2025-07-21T09:57:37.237136",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9292a7c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T09:57:37.246265Z",
     "iopub.status.busy": "2025-07-21T09:57:37.246021Z",
     "iopub.status.idle": "2025-07-21T09:57:37.252286Z",
     "shell.execute_reply": "2025-07-21T09:57:37.251657Z"
    },
    "papermill": {
     "duration": 0.010682,
     "end_time": "2025-07-21T09:57:37.253383",
     "exception": false,
     "start_time": "2025-07-21T09:57:37.242701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'W1': array([[0.1, 0.1],\n",
      "       [0.1, 0.1]]), 'b1': array([[0.],\n",
      "       [0.]]), 'W2': array([[0.1, 0.1]]), 'b2': array([[0.]])}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def initialize_parameters(layer_dims):\n",
    "    np.random.seed(3)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)\n",
    "\n",
    "    for i in range(1, L):\n",
    "        parameters['W' + str(i)] = np.ones((layer_dims[i], layer_dims[i - 1])) * 0.1\n",
    "        parameters['b' + str(i)] = np.zeros((layer_dims[i], 1))\n",
    "\n",
    "    return parameters\n",
    "\n",
    "# Example call\n",
    "params = initialize_parameters([2, 2, 1])\n",
    "print(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3328ebce",
   "metadata": {
    "papermill": {
     "duration": 0.002644,
     "end_time": "2025-07-21T09:57:37.258852",
     "exception": false,
     "start_time": "2025-07-21T09:57:37.256208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4246c0ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T09:57:37.265230Z",
     "iopub.status.busy": "2025-07-21T09:57:37.265019Z",
     "iopub.status.idle": "2025-07-21T09:58:14.451253Z",
     "shell.execute_reply": "2025-07-21T09:58:14.450204Z"
    },
    "papermill": {
     "duration": 37.19115,
     "end_time": "2025-07-21T09:58:14.452715",
     "exception": false,
     "start_time": "2025-07-21T09:57:37.261565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-21 09:57:39.245094: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753091859.519191      13 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753091859.594825      13 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-07-21 09:57:54.984487: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Predictions:\n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# Step 1: XOR Input & Output\n",
    "X = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "Y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "# Step 2: Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim=2, activation='relu'))  # Hidden layer\n",
    "model.add(Dense(1, activation='sigmoid'))            # Output layer\n",
    "\n",
    "# Step 3: Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=SGD(learning_rate=0.1), metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Train the model\n",
    "model.fit(X, Y, epochs=500, verbose=0)\n",
    "\n",
    "# Step 5: Evaluate\n",
    "predictions = model.predict(X)\n",
    "print(\"Predictions:\\n\", np.round(predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "280419c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T09:58:14.460940Z",
     "iopub.status.busy": "2025-07-21T09:58:14.460260Z",
     "iopub.status.idle": "2025-07-21T09:58:14.520735Z",
     "shell.execute_reply": "2025-07-21T09:58:14.519853Z"
    },
    "papermill": {
     "duration": 0.065909,
     "end_time": "2025-07-21T09:58:14.522146",
     "exception": false,
     "start_time": "2025-07-21T09:58:14.456237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.9508767\n",
      "Gradients:\n",
      "dW1 shape: (2, 4)\n",
      "db1 shape: (4,)\n",
      "dW2 shape: (4, 1)\n",
      "db2 shape: (1,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(1,) dtype=float32, numpy=array([0.02521864], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Sample data (XOR logic)\n",
    "X = tf.constant([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=tf.float32)\n",
    "Y = tf.constant([[0], [1], [1], [0]], dtype=tf.float32)\n",
    "\n",
    "# Step 2: Define model weights manually\n",
    "W1 = tf.Variable(tf.random.normal((2, 4)), dtype=tf.float32)  # (input_dim, hidden_dim)\n",
    "b1 = tf.Variable(tf.zeros((4,)), dtype=tf.float32)\n",
    "\n",
    "W2 = tf.Variable(tf.random.normal((4, 1)), dtype=tf.float32)  # (hidden_dim, output_dim)\n",
    "b2 = tf.Variable(tf.zeros((1,)), dtype=tf.float32)\n",
    "\n",
    "# Step 3: Define learning rate\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Step 4: Use GradientTape for forward + backward pass\n",
    "with tf.GradientTape() as tape:\n",
    "    # Forward pass\n",
    "    Z1 = tf.matmul(X, W1) + b1         # Shape: (4, 4)\n",
    "    A1 = tf.nn.relu(Z1)                # Shape: (4, 4)\n",
    "    Z2 = tf.matmul(A1, W2) + b2        # Shape: (4, 1)\n",
    "    A2 = tf.nn.sigmoid(Z2)             # Final output\n",
    "\n",
    "    # Loss (binary crossentropy)\n",
    "    loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(Y, A2))\n",
    "\n",
    "# Step 5: Compute gradients\n",
    "grads = tape.gradient(loss, [W1, b1, W2, b2])\n",
    "\n",
    "# Step 6: Print gradients and their shapes\n",
    "print(\"Loss:\", loss.numpy())\n",
    "print(\"Gradients:\")\n",
    "print(\"dW1 shape:\", grads[0].shape)  # (2, 4)\n",
    "print(\"db1 shape:\", grads[1].shape)  # (4,)\n",
    "print(\"dW2 shape:\", grads[2].shape)  # (4, 1)\n",
    "print(\"db2 shape:\", grads[3].shape)  # (1,)\n",
    "\n",
    "# Step 7: Optional - Update weights manually\n",
    "W1.assign_sub(learning_rate * grads[0])\n",
    "b1.assign_sub(learning_rate * grads[1])\n",
    "W2.assign_sub(learning_rate * grads[2])\n",
    "b2.assign_sub(learning_rate * grads[3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7092c77",
   "metadata": {
    "papermill": {
     "duration": 0.003359,
     "end_time": "2025-07-21T09:58:14.529330",
     "exception": false,
     "start_time": "2025-07-21T09:58:14.525971",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Code from the keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3f2f403",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T09:58:14.537392Z",
     "iopub.status.busy": "2025-07-21T09:58:14.537105Z",
     "iopub.status.idle": "2025-07-21T09:58:14.542201Z",
     "shell.execute_reply": "2025-07-21T09:58:14.541682Z"
    },
    "papermill": {
     "duration": 0.010383,
     "end_time": "2025-07-21T09:58:14.543261",
     "exception": false,
     "start_time": "2025-07-21T09:58:14.532878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow \n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "058522da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T09:58:14.550446Z",
     "iopub.status.busy": "2025-07-21T09:58:14.550212Z",
     "iopub.status.idle": "2025-07-21T09:58:14.557616Z",
     "shell.execute_reply": "2025-07-21T09:58:14.556683Z"
    },
    "papermill": {
     "duration": 0.012685,
     "end_time": "2025-07-21T09:58:14.559098",
     "exception": false,
     "start_time": "2025-07-21T09:58:14.546413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cgpa</th>\n",
       "      <th>profile</th>\n",
       "      <th>lpa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cgpa  profile  lpa\n",
       "0     8        8    4\n",
       "1     7        9    5\n",
       "2     6       10    6\n",
       "3     5       12    7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f330a881",
   "metadata": {
    "papermill": {
     "duration": 0.00316,
     "end_time": "2025-07-21T09:58:14.565985",
     "exception": false,
     "start_time": "2025-07-21T09:58:14.562825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 47.577151,
   "end_time": "2025-07-21T09:58:17.936161",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-21T09:57:30.359010",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
